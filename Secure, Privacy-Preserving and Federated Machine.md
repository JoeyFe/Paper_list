Secure, Privacy-Preserving and Federated Machine
===
主要提出了四个主要问题：
1.通信开销太大
2.不同的设备的系统是异质的
3.不同设备上面的数据也是异质的
4.联邦学习中的安全和隐私问题

## 解决办法：

提高通讯效率：局部更新办法、数据压缩办法，去中心化训练方式
系统异质性解决办法：异步通信、动态采样、容错控制？这个看不太懂
数据异质性（解决各方数据不满足独立同分布的问题）：通过元学习和多任务的方式训练，加快收敛的方法FedProx论文。
隐私：跟之前联邦学习书中所列举的差不多。

## 未来发展观点：

**特殊的通讯方案：** 在联邦学习中，有多少交流是必要的，还有待观察。事实上，众所周知，机器学习的优化方法可以容忍精度的不足；这个错误实际上有助于泛化[129]。虽然在传统的数据中心环境中已经探索了单点或分而治之的通信方案[73,137]，但在大规模或统计异构网络中，这些方法的行为并没有得到很好的理解。类似地，最近为联邦设置提出了一次/几次试探法[44,45,134]，但尚未从理论上进行分析或按比例进行评估。

**减少通信负载，Pareto frontier最优化：** 我们讨论了在联邦训练中减少通信的几种方法，如局部更新和模型压缩。为了创建一个真实的联邦学习系统，了解这些技术是如何相互组合的，并且系统地分析每种方法的准确性和通信之间的权衡是很重要的。特别是，最有用的技术将展示Pareto frontier的改进，在相同的通信预算下，在理想情况下，在广泛的通信/精度剖面上，实现比任何其他方法更高的精度。为了有效地进行神经网络推理，已经进行了类似的综合分析，并且为了以有意义的方式比较用于联邦学习的通信简化技术是必要的。

**异步模型：** 分布式优化中最常研究的两种通信方案是批量同步方法和异步方法（假设延迟是有界的）。这些方案在数据中心设置中更为实际，其中工作节点通常专用于工作负载，即，它们准备在“推送”上一个作业的结果后立即从中心节点“拉取”下一个作业。相比之下，在联邦网络中，每个设备通常不被分配给手头的任务，并且大多数设备在任何给定的迭代中都不活动。因此，值得研究这种更现实的以设备为中心的通信方案的效果，其中每个设备可以决定何时“唤醒”，并以事件触发的方式与中央服务器交互。

**异质性诊断：** 最近的研究旨在通过诸如计算局部差异性、或者用一些指标量化统计异质性。然而，在训练发生之前，这些度量不能通过联邦网络轻松计算这些度量的重要性，激发了以下开放性问题：（i）是否存在简单的方法能快速确定联邦网络中的异质性水平？（ii）是否可以开发类似的诊断来量化与系统相关的异质性的数量？（iii）是否可以利用当前或新的异质性定义来进一步改进联邦优化方法的收敛性？

**细微的隐私限制：** 在更细粒度级别上定义隐私，因为隐私约束可能在设备之间或甚至在单个设备上的数据点之间有所不同。例如，最近提出了样本特定（相对于用户特定）的隐私保证，从而提供了一种较弱的隐私形式，以换取更精确的模型。开发处理混合（设备特定或样本特定）隐私限制的方法是未来工作的一个有趣和持续的方向。

**无监督/弱监督学习：** 重要的是要注意到，迄今为止讨论的方法都是随着监督学习的任务而发展起来的，即他们假设联邦网络中的所有数据都存在标签。实际上，在实际的联邦网络中生成的许多数据可能是未标记或弱标记的。此外，目前的问题可能不是将模型与（1）中所示的数据拟合，而是执行一些探索性数据分析、确定聚合统计数据或运行更复杂的任务，如强化学习。在联邦网络中解决监督学习以外的问题可能需要解决可伸缩性、异构性和隐私性方面的类似挑战。

**工业化联邦学习：** 除了本文讨论的主要挑战之外，在产品环境中运行联邦学习时还需要考虑一些实际问题。尤其是概念漂移（当底层数据生成模型随时间变化时）；日变化（当设备在一天或一周的不同时间表现出不同的行为时）；冷启动问题（当新设备进入网络时）等问题必须小心处理。我们将读者推荐到[11]，这篇文章讨论了产品性联邦学习系统中存在的一些与实际系统相关的问题。

**BASELINE框架：** 最后，由于联邦学习是一个新兴的领域，我们正处于一个关键时刻，以塑造这一领域的发展，并确保它们以现实世界的环境、假设和数据集为基础。对于更广泛的研究界来说，进一步建立在现有的实现和基准工具上，如LEAF[16]和Tensorflow Federated[1]是至关重要的，以促进经验结果的可重复性和联邦学习的新解决方案的传播。
